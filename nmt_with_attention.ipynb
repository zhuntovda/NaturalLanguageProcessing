{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"nmt_with_attention.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"J0Qjg6vuaHNt"},"source":["# Neural machine translation with attention"]},{"cell_type":"code","metadata":{"id":"tnxXKDjq3jEL","executionInfo":{"status":"ok","timestamp":1637930796819,"user_tz":-300,"elapsed":3531,"user":{"displayName":"Денис Жунтов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03398161046237101130"}}},"source":["import tensorflow as tf\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","from sklearn.model_selection import train_test_split\n","\n","import unicodedata\n","import re\n","import numpy as np\n","import os\n","import io\n","import time"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wfodePkj3jEa"},"source":["## Download and prepare the dataset\n","\n","We'll use a language dataset provided by http://www.manythings.org/anki/"]},{"cell_type":"code","metadata":{"id":"CNvjhDyAKk3U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637930796819,"user_tz":-300,"elapsed":7,"user":{"displayName":"Денис Жунтов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03398161046237101130"}},"outputId":"ebbb5ff4-33b2-40ab-a74e-949d2fdd6607"},"source":["!wget http://www.manythings.org/anki/rus-eng.zip"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["--2021-11-26 12:46:36--  http://www.manythings.org/anki/rus-eng.zip\n","Resolving www.manythings.org (www.manythings.org)... 172.67.186.54, 104.21.92.44, 2606:4700:3030::6815:5c2c, ...\n","Connecting to www.manythings.org (www.manythings.org)|172.67.186.54|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 14385451 (14M) [application/zip]\n","Saving to: ‘rus-eng.zip.1’\n","\n","\rrus-eng.zip.1         0%[                    ]       0  --.-KB/s               \rrus-eng.zip.1       100%[===================>]  13.72M  --.-KB/s    in 0.07s   \n","\n","2021-11-26 12:46:36 (210 MB/s) - ‘rus-eng.zip.1’ saved [14385451/14385451]\n","\n"]}]},{"cell_type":"code","metadata":{"id":"83bg17Lr-7XK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637935310481,"user_tz":-300,"elapsed":4513665,"user":{"displayName":"Денис Жунтов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03398161046237101130"}},"outputId":"fe522c58-349f-460a-902a-0691b9c65f7b"},"source":["!mkdir rus-eng\n","!unzip rus-eng.zip -d rus-eng/"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["mkdir: cannot create directory ‘rus-eng’: File exists\n","Archive:  rus-eng.zip\n","replace rus-eng/rus.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n","  inflating: rus-eng/rus.txt         \n","  inflating: rus-eng/_about.txt      \n"]}]},{"cell_type":"code","metadata":{"id":"7o5L92efMMhf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637935310481,"user_tz":-300,"elapsed":16,"user":{"displayName":"Денис Жунтов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03398161046237101130"}},"outputId":"d4805c34-a89e-4fe9-cd50-9fee6f17485a"},"source":["!ls /content/rus-eng/ -lah"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["total 69M\n","drwxr-xr-x 2 root root 4.0K Nov 26 14:01 .\n","drwxr-xr-x 1 root root 4.0K Nov 26 12:46 ..\n","-rw-r--r-- 1 root root 1.5K Jul 14 10:16 _about.txt\n","-rw-r--r-- 1 root root  69M Jul 14 10:16 rus.txt\n"]}]},{"cell_type":"code","metadata":{"id":"kRVATYOgJs1b","executionInfo":{"status":"ok","timestamp":1637935310482,"user_tz":-300,"elapsed":8,"user":{"displayName":"Денис Жунтов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03398161046237101130"}}},"source":["# Download the file\n","path_to_file = \"/content/rus-eng/rus.txt\""],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"rd0jw-eC3jEh","executionInfo":{"status":"ok","timestamp":1637935310482,"user_tz":-300,"elapsed":7,"user":{"displayName":"Денис Жунтов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03398161046237101130"}}},"source":["def preprocess_sentence(w):\n","  w = w.lower().strip()\n","\n","  # creating a space between a word and the punctuation following it\n","  # eg: \"he is a boy.\" => \"he is a boy .\"\n","  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n","  w = re.sub(r\"([?.!,])\", r\" \\1 \", w)\n","  w = re.sub(r'[\" \"]+', \" \", w)\n","\n","  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n","  w = re.sub(r\"[^a-zA-Zа-яА-Я?.!,']+\", \" \", w)\n","\n","  w = w.strip()\n","\n","  # adding a start and an end token to the sentence\n","  # so that the model know when to start and stop predicting.\n","  w = '<start> ' + w + ' <end>'\n","  return w"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"yV9lZXQXNbnH","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1637935310482,"user_tz":-300,"elapsed":6,"user":{"displayName":"Денис Жунтов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03398161046237101130"}},"outputId":"0f10aaf5-6dab-467e-b46e-9d01276dc8f7"},"source":["preprocess_sentence(\"I can't go.\")"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"<start> i can't go . <end>\""]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"OHn4Dct23jEm","executionInfo":{"status":"ok","timestamp":1637935310482,"user_tz":-300,"elapsed":5,"user":{"displayName":"Денис Жунтов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03398161046237101130"}}},"source":["# 1. Remove the accents\n","# 2. Clean the sentences\n","# 3. Return word pairs in the format: [ENG, RUS]\n","def create_dataset(path, num_examples):\n","  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n","\n","  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')[:2]]  for l in lines[:num_examples]]\n","\n","  return zip(*word_pairs)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"cTbSbBz55QtF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637935324129,"user_tz":-300,"elapsed":13652,"user":{"displayName":"Денис Жунтов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03398161046237101130"}},"outputId":"f8de2bc7-1d41-4dd5-b12d-1283d5184ea7"},"source":["en, ru = create_dataset(path_to_file, None)\n","print(en[-1])\n","print(ru[-1])"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["<start> doubtless there exists in this world precisely the right woman for any given man to marry and vice versa but when you consider that a human being has the opportunity of being acquainted with only a few hundred people , and out of the few hundred that there are but a dozen or less whom he knows intimately , and out of the dozen , one or two friends at most , it will easily be seen , when we remember the number of millions who inhabit this world , that probably , since the earth was created , the right man has never yet met the right woman . <end>\n","<start> несомненно , для каждого мужчины в этом мире где то есть подходящая женщина , которая может стать ему женой , обратное верно и для женщин . но если учесть , что у человека может быть максимум несколько сотен знакомых , из которых лишь дюжина , а то и меньше , тех , кого он знает близко , а из этой дюжины у него один или от силы два друга , то можно легко увидеть , что с уч том миллионов живущих на земле людей , ни один подходящий мужчина , возможно , ещ не встретил подходящую женщину . <end>\n"]}]},{"cell_type":"code","metadata":{"id":"bIOn8RCNDJXG","executionInfo":{"status":"ok","timestamp":1637935324129,"user_tz":-300,"elapsed":12,"user":{"displayName":"Денис Жунтов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03398161046237101130"}}},"source":["def tokenize(lang):\n","  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n","      filters='')\n","  lang_tokenizer.fit_on_texts(lang)\n","\n","  tensor = lang_tokenizer.texts_to_sequences(lang)\n","\n","  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n","                                                         padding='post')\n","\n","  return tensor, lang_tokenizer"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"eAY9k49G3jE_","executionInfo":{"status":"ok","timestamp":1637935324129,"user_tz":-300,"elapsed":11,"user":{"displayName":"Денис Жунтов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03398161046237101130"}}},"source":["def load_dataset(path, num_examples=None):\n","  # creating cleaned input, output pairs\n","  targ_lang, inp_lang = create_dataset(path, num_examples)\n","\n","  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n","  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n","\n","  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GOi42V79Ydlr"},"source":["### Limit the size of the dataset to experiment faster (optional)\n"]},{"cell_type":"code","metadata":{"id":"C8j9g9AnIeZV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637935324130,"user_tz":-300,"elapsed":12,"user":{"displayName":"Денис Жунтов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03398161046237101130"}},"outputId":"a955108d-35e2-4a26-e901-e0e64fa57bf6"},"source":["len(en), len(ru)"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(431097, 431097)"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"cnxC7q-j3jFD","executionInfo":{"status":"ok","timestamp":1637935331702,"user_tz":-300,"elapsed":7582,"user":{"displayName":"Денис Жунтов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03398161046237101130"}}},"source":["# Try experimenting with the size of that dataset\n","num_examples = 100000\n","input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n","\n","# Calculate max_length of the target tensors\n","max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"4QILQkOs3jFG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637935331703,"user_tz":-300,"elapsed":10,"user":{"displayName":"Денис Жунтов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03398161046237101130"}},"outputId":"b657d83d-c776-4c3c-fa5d-60af5df24cb7"},"source":["# Creating training and validation sets using an 80-20 split\n","input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n","\n","# Show length\n","print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["80000 80000 20000 20000\n"]}]},{"cell_type":"code","metadata":{"id":"lJPmLZGMeD5q","executionInfo":{"status":"ok","timestamp":1637935331703,"user_tz":-300,"elapsed":7,"user":{"displayName":"Денис Жунтов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03398161046237101130"}}},"source":["def convert(lang, tensor):\n","  for t in tensor:\n","    if t!=0:\n","      print (\"%d ----> %s\" % (t, lang.index_word[t]))"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"VXukARTDd7MT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637935331703,"user_tz":-300,"elapsed":7,"user":{"displayName":"Денис Жунтов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03398161046237101130"}},"outputId":"498c4abf-45f9-4ef4-ed5b-d846321ecb53"},"source":["print (\"Input Language; index to word mapping\")\n","convert(inp_lang, input_tensor_train[0])\n","print ()\n","print (\"Target Language; index to word mapping\")\n","convert(targ_lang, target_tensor_train[0])"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Input Language; index to word mapping\n","1 ----> <start>\n","4 ----> я\n","29 ----> его\n","2132 ----> исправил\n","3 ----> .\n","2 ----> <end>\n","\n","Target Language; index to word mapping\n","1 ----> <start>\n","4 ----> i\n","1716 ----> corrected\n","10 ----> it\n","3 ----> .\n","2 ----> <end>\n"]}]},{"cell_type":"markdown","metadata":{"id":"rgCLkfv5uO3d"},"source":["### Create a tf.data dataset"]},{"cell_type":"code","metadata":{"id":"TqHsArVZ3jFS","executionInfo":{"status":"ok","timestamp":1637935331703,"user_tz":-300,"elapsed":5,"user":{"displayName":"Денис Жунтов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03398161046237101130"}}},"source":["BUFFER_SIZE = len(input_tensor_train)\n","BATCH_SIZE = 64\n","steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n","embedding_dim = 256\n","units = 1024\n","vocab_inp_size = len(inp_lang.word_index)+1\n","vocab_tar_size = len(targ_lang.word_index)+1\n","\n","dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n","dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"qc6-NK1GtWQt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637935331704,"user_tz":-300,"elapsed":6,"user":{"displayName":"Денис Жунтов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03398161046237101130"}},"outputId":"079fa49a-88f0-4c29-df1e-d41e6d22be08"},"source":["example_input_batch, example_target_batch = next(iter(dataset))\n","example_input_batch.shape, example_target_batch.shape"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(TensorShape([64, 15]), TensorShape([64, 11]))"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"nZ2rI24i3jFg","executionInfo":{"status":"ok","timestamp":1637935331704,"user_tz":-300,"elapsed":5,"user":{"displayName":"Денис Жунтов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03398161046237101130"}}},"source":["class Encoder(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n","    super(Encoder, self).__init__()\n","    self.batch_sz = batch_sz\n","    self.enc_units = enc_units\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.gru1 = tf.keras.layers.GRU(self.enc_units,\n","                                   return_sequences=True,\n","                                   return_state=False,\n","                                   recurrent_initializer='glorot_uniform')\n","    self.gru2 = tf.keras.layers.GRU(self.enc_units,\n","                                   return_sequences=False,\n","                                   return_state=True,\n","                                   recurrent_initializer='glorot_uniform')\n","\n","  def call(self, x, hidden):\n","    x = self.embedding(x)\n","    x = self.gru1(x, initial_state = hidden)\n","    output, state = self.gru2(x, initial_state = hidden)\n","    return output, state\n","\n","  def initialize_hidden_state(self):\n","    return tf.zeros((self.batch_sz, self.enc_units))"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"60gSVh05Jl6l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637935332628,"user_tz":-300,"elapsed":928,"user":{"displayName":"Денис Жунтов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03398161046237101130"}},"outputId":"555194d2-e93e-4cf3-8ac6-97d249d308db"},"source":["encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n","\n","# sample input\n","sample_hidden = encoder.initialize_hidden_state()\n","sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n","print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n","print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Encoder output shape: (batch size, sequence length, units) (64, 1024)\n","Encoder Hidden state shape: (batch size, units) (64, 1024)\n"]}]},{"cell_type":"code","metadata":{"id":"YTyhL28Niqk1","executionInfo":{"status":"ok","timestamp":1637935332628,"user_tz":-300,"elapsed":4,"user":{"displayName":"Денис Жунтов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03398161046237101130"}}},"source":["class BahdanauAttention(tf.keras.layers.Layer):\n","  def __init__(self, units):\n","    super(BahdanauAttention, self).__init__()\n","    self.W1 = tf.keras.layers.Dense(units)\n","    self.W2 = tf.keras.layers.Dense(units)\n","    self.V = tf.keras.layers.Dense(1)\n","\n","  def call(self, query, values):\n","    # query hidden state shape == (batch_size, hidden size)\n","    # query_with_time_axis shape == (batch_size, 1, hidden size)\n","    # values shape == (batch_size, max_len, hidden size)\n","    # we are doing this to broadcast addition along the time axis to calculate the score\n","    query_with_time_axis = tf.expand_dims(query, 1)\n","\n","    # score shape == (batch_size, max_length, 1)\n","    # we get 1 at the last axis because we are applying score to self.V\n","    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n","    score = self.V(tf.nn.tanh(\n","        self.W1(query_with_time_axis) + self.W2(values)))\n","\n","    # attention_weights shape == (batch_size, max_length, 1)\n","    attention_weights = tf.nn.softmax(score, axis=1)\n","\n","    # context_vector shape after sum == (batch_size, hidden_size)\n","    context_vector = attention_weights * values\n","    context_vector = tf.reduce_sum(context_vector, axis=1)\n","\n","    return context_vector, attention_weights"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XUqssWcci1XJ","executionInfo":{"status":"ok","timestamp":1637935332629,"user_tz":-300,"elapsed":4,"user":{"displayName":"Денис Жунтов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03398161046237101130"}},"outputId":"98c5bf36-0e3d-48c4-a957-501615034627"},"source":["attention_layer = BahdanauAttention(12)\n","attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n","\n","print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n","print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Attention result shape: (batch size, units) (64, 1024)\n","Attention weights shape: (batch_size, sequence_length, 1) (64, 64, 1)\n"]}]},{"cell_type":"code","metadata":{"id":"yJ_B3mhW3jFk","executionInfo":{"status":"ok","timestamp":1637935332629,"user_tz":-300,"elapsed":3,"user":{"displayName":"Денис Жунтов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03398161046237101130"}}},"source":["class Decoder(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n","    super(Decoder, self).__init__()\n","    self.batch_sz = batch_sz\n","    self.dec_units = dec_units\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.gru1 = tf.keras.layers.GRU(self.dec_units,\n","                                   return_sequences=True,\n","                                   return_state=False,\n","                                   recurrent_initializer='glorot_uniform')\n","    self.gru2 = tf.keras.layers.GRU(self.dec_units,\n","                                   return_sequences=True,\n","                                   return_state=True,\n","                                   recurrent_initializer='glorot_uniform')\n","    self.fc = tf.keras.layers.Dense(vocab_size)\n","\n","    # used for attention\n","    self.attention = BahdanauAttention(self.dec_units)\n","\n","  def call(self, x, hidden, enc_output):\n","    # enc_output shape == (batch_size, max_length, hidden_size)\n","    context_vector, attention_weights = self.attention(hidden, enc_output)\n","\n","    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n","    x = self.embedding(x)\n","\n","    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n","    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n","\n","    # passing the concatenated vector to the GRU\n","    x = self.gru1(x, initial_state = hidden)\n","    output, state = self.gru2(x, initial_state = hidden)\n","\n","    # output shape == (batch_size * 1, hidden_size)\n","    output = tf.reshape(output, (-1, output.shape[2]))\n","\n","    # output shape == (batch_size, vocab)\n","    x = self.fc(output)\n","\n","    return x, state, attention_weights"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"P5UY8wko3jFp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637935332902,"user_tz":-300,"elapsed":275,"user":{"displayName":"Денис Жунтов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03398161046237101130"}},"outputId":"d6e8939c-246c-4622-9d65-ad26c25b19cd"},"source":["decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n","\n","sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n","                                      sample_hidden, sample_output)\n","\n","print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Decoder output shape: (batch_size, vocab size) (64, 7260)\n"]}]},{"cell_type":"markdown","metadata":{"id":"_ch_71VbIRfK"},"source":["## Define the optimizer and the loss function"]},{"cell_type":"code","metadata":{"id":"WmTHr5iV3jFr","executionInfo":{"status":"ok","timestamp":1637935333181,"user_tz":-300,"elapsed":283,"user":{"displayName":"Денис Жунтов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03398161046237101130"}}},"source":["optimizer = tf.keras.optimizers.Adam()\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=True, reduction='none')\n","\n","def loss_function(real, pred):\n","  mask = tf.math.logical_not(tf.math.equal(real, 0))\n","  loss_ = loss_object(real, pred)\n","\n","  mask = tf.cast(mask, dtype=loss_.dtype)\n","  loss_ *= mask\n","\n","  return tf.reduce_mean(loss_)"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DMVWzzsfNl4e"},"source":["## Checkpoints (Object-based saving)"]},{"cell_type":"code","metadata":{"id":"Zj8bXQTgNwrF","executionInfo":{"status":"ok","timestamp":1637935333182,"user_tz":-300,"elapsed":2,"user":{"displayName":"Денис Жунтов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03398161046237101130"}}},"source":["checkpoint_dir = './training_attention_checkpoints'\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n","checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n","                                 encoder=encoder,\n","                                 decoder=decoder)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"sC9ArXSsVfqn","executionInfo":{"status":"ok","timestamp":1637935333182,"user_tz":-300,"elapsed":2,"user":{"displayName":"Денис Жунтов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03398161046237101130"}}},"source":["@tf.function\n","def train_step(inp, targ, enc_hidden):\n","  loss = 0\n","\n","  with tf.GradientTape() as tape:\n","    enc_output, enc_hidden = encoder(inp, enc_hidden)\n","\n","    dec_hidden = enc_hidden\n","\n","    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n","\n","    # Teacher forcing - feeding the target as the next input\n","    for t in range(1, targ.shape[1]):\n","      # passing enc_output to the decoder\n","      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n","\n","      loss += loss_function(targ[:, t], predictions)\n","\n","      # using teacher forcing\n","      dec_input = tf.expand_dims(targ[:, t], 1)\n","\n","  batch_loss = (loss / int(targ.shape[1]))\n","\n","  variables = encoder.trainable_variables + decoder.trainable_variables\n","\n","  gradients = tape.gradient(loss, variables)\n","\n","  optimizer.apply_gradients(zip(gradients, variables))\n","\n","  return batch_loss"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"ddefjBMa3jF0","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ee9d0467-b109-4ca6-9403-e3ad4d45d165"},"source":["EPOCHS = 50\n","\n","for epoch in range(EPOCHS):\n","  start = time.time()\n","\n","  enc_hidden = encoder.initialize_hidden_state()\n","  total_loss = 0\n","\n","  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n","    batch_loss = train_step(inp, targ, enc_hidden)\n","    total_loss += batch_loss\n","\n","    if batch % 100 == 0:\n","      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n","                                                   batch,\n","                                                   batch_loss.numpy()))\n","  # saving (checkpoint) the model every 2 epochs\n","  if (epoch + 1) % 2 == 0:\n","    checkpoint.save(file_prefix = checkpoint_prefix)\n","\n","  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n","                                      total_loss / steps_per_epoch))\n","  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 Batch 0 Loss 4.6975\n","Epoch 1 Batch 100 Loss 2.3375\n","Epoch 1 Batch 200 Loss 2.1777\n","Epoch 1 Batch 300 Loss 1.9108\n","Epoch 1 Batch 400 Loss 1.9127\n","Epoch 1 Batch 500 Loss 1.6742\n","Epoch 1 Batch 600 Loss 1.6371\n","Epoch 1 Batch 700 Loss 1.5675\n","Epoch 1 Batch 800 Loss 1.4713\n","Epoch 1 Batch 900 Loss 1.4333\n","Epoch 1 Batch 1000 Loss 1.4832\n","Epoch 1 Batch 1100 Loss 1.3691\n","Epoch 1 Batch 1200 Loss 1.4315\n","Epoch 1 Loss 1.7109\n","Time taken for 1 epoch 7341.934864044189 sec\n","\n","Epoch 2 Batch 0 Loss 1.2384\n","Epoch 2 Batch 100 Loss 1.1667\n","Epoch 2 Batch 200 Loss 1.1500\n","Epoch 2 Batch 300 Loss 1.0759\n","Epoch 2 Batch 400 Loss 1.0205\n","Epoch 2 Batch 500 Loss 1.0293\n","Epoch 2 Batch 600 Loss 1.1355\n","Epoch 2 Batch 700 Loss 1.0004\n","Epoch 2 Batch 800 Loss 0.9379\n","Epoch 2 Batch 900 Loss 0.9783\n","Epoch 2 Batch 1000 Loss 0.8753\n","Epoch 2 Batch 1100 Loss 0.7202\n","Epoch 2 Batch 1200 Loss 0.8240\n","Epoch 2 Loss 0.9892\n","Time taken for 1 epoch 7687.392162799835 sec\n","\n","Epoch 3 Batch 0 Loss 0.6145\n","Epoch 3 Batch 100 Loss 0.7003\n","Epoch 3 Batch 200 Loss 0.6698\n","Epoch 3 Batch 300 Loss 0.6433\n","Epoch 3 Batch 400 Loss 0.6463\n","Epoch 3 Batch 500 Loss 0.6449\n","Epoch 3 Batch 600 Loss 0.5647\n","Epoch 3 Batch 700 Loss 0.6077\n"]}]},{"cell_type":"markdown","metadata":{"id":"mU3Ce8M6I3rz"},"source":["## Translate\n","\n","* The evaluate function is similar to the training loop, except we don't use *teacher forcing* here. The input to the decoder at each time step is its previous predictions along with the hidden state and the encoder output.\n","* Stop predicting when the model predicts the *end token*.\n","* And store the *attention weights for every time step*.\n","\n","Note: The encoder output is calculated only once for one input."]},{"cell_type":"code","metadata":{"id":"EbQpyYs13jF_"},"source":["def evaluate(sentence):\n","  attention_plot = np.zeros((max_length_targ, max_length_inp))\n","\n","  sentence = preprocess_sentence(sentence)\n","\n","  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n","  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n","                                                         maxlen=max_length_inp,\n","                                                         padding='post')\n","  inputs = tf.convert_to_tensor(inputs)\n","\n","  result = ''\n","\n","  hidden = [tf.zeros((1, units))]\n","  enc_out, enc_hidden = encoder(inputs, hidden)\n","\n","  dec_hidden = enc_hidden\n","  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n","\n","  for t in range(max_length_targ):\n","    predictions, dec_hidden, attention_weights = decoder(dec_input,\n","                                                         dec_hidden,\n","                                                         enc_out)\n","\n","    # storing the attention weights to plot later on\n","    attention_weights = tf.reshape(attention_weights, (-1, ))\n","    attention_plot[t] = attention_weights.numpy()\n","\n","    predicted_id = tf.argmax(predictions[0]).numpy()\n","\n","    result += targ_lang.index_word[predicted_id] + ' '\n","\n","    if targ_lang.index_word[predicted_id] == '<end>':\n","      return result, sentence, attention_plot\n","\n","    # the predicted ID is fed back into the model\n","    dec_input = tf.expand_dims([predicted_id], 0)\n","\n","  return result, sentence, attention_plot"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qjy26Fe8Bv5d"},"source":["# function for plotting the attention weights\n","def plot_attention(attention, sentence, predicted_sentence):\n","  fig = plt.figure(figsize=(10,10))\n","  ax = fig.add_subplot(1, 1, 1)\n","  ax.matshow(attention, cmap='viridis')\n","\n","  fontdict = {'fontsize': 14}\n","\n","  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n","  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n","\n","  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n","  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n","\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sl9zUHzg3jGI"},"source":["def translate(sentence):\n","  result, sentence, attention_plot = evaluate(sentence)\n","\n","  print('Input: %s' % (sentence))\n","  print('Predicted translation: {}'.format(result))\n","\n","  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n","  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n250XbnjOaqP"},"source":["## Restore the latest checkpoint and test"]},{"cell_type":"code","metadata":{"id":"UJpT9D5_OgP6"},"source":["# restoring the latest checkpoint in checkpoint_dir\n","checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WrAM0FDomq3E"},"source":["translate('Здесь хорошо.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5bhFfwcIMX5i"},"source":["translate('Я не смогу поехать.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zSx2iM36EZQZ"},"source":["translate(u'Вы еще дома?')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A3LLCx3ZE0Ls"},"source":["translate(u'Вы все еще дома?')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DUQVLVqUE1YW"},"source":["translate(u'Попробуй сделать это.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f09_hUFx9EJh"},"source":["translate(u'Я не люблю, когда идет снег.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e7c5p8rmkHQG"},"source":["translate(u'Я никогда такого не делаю.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jdXES85KkTVS"},"source":[""],"execution_count":null,"outputs":[]}]}